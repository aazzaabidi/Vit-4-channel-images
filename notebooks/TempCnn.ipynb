# resnet50.py
import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.layers import (Conv2D, BatchNormalization, Activation, 
                                    MaxPooling2D, Add, GlobalAveragePooling2D, 
                                    Flatten, Dense, Input)
import numpy as np
import os
from sklearn.preprocessing import LabelEncoder
from utils.metrics import calculate_metrics, print_metrics_summary
from utils.visualization import save_visualizations

class ResNet50:
    def __init__(self, input_shape, num_classes, model_dir="saved_models"):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model_dir = model_dir
        self.model = self._build_model()
        os.makedirs(self.model_dir, exist_ok=True)  # Create save directory
    
    def _residual_block(self, X_start, filters, name, reduce=False, res_conv2d=False):
        """Residual block implementation for ResNet50"""
        nb_filters_1, nb_filters_2, nb_filters_3 = filters
        strides_1 = [2,2] if reduce else [1,1]

        X = Conv2D(filters=nb_filters_1, kernel_size=[1,1], strides=strides_1, 
                  padding='same', name=f'{name}_conv1')(X_start)
        X = BatchNormalization(name=f'{name}_bn1')(X)
        X = Activation('relu')(X)

        X = Conv2D(filters=nb_filters_2, kernel_size=[3,3], strides=[1,1], 
                  padding='same', name=f'{name}_conv2')(X)
        X = BatchNormalization(name=f'{name}_bn2')(X)
        X = Activation('relu')(X)

        X = Conv2D(filters=nb_filters_3, kernel_size=[1,1], strides=[1,1], 
                  padding='same', name=f'{name}_conv3')(X)
        X = BatchNormalization(name=f'{name}_bn3')(X)

        if res_conv2d:
            X_res = Conv2D(filters=nb_filters_3, kernel_size=[1,1], strides=strides_1, 
                         padding='same', name=f'{name}_conv_res')(X_start)
            X_res = BatchNormalization(name=f'{name}_bn_res')(X_res)
        else:
            X_res = X_start

        X = Add(name=f'{name}_add')([X, X_res])
        return Activation('relu', name=f'{name}_relu')(X)

    def _build_model(self):
        """Constructs the ResNet50 architecture"""
        X_input = Input(shape=self.input_shape, name='input')

        # [Previous architecture code remains exactly the same...]
        # ... (include all your residual blocks exactly as before)

        return Model(inputs=X_input, outputs=outputs, name='ResNet50')

    def _get_model_checkpoint(self, model_name):
        """Helper to create model checkpoint callback"""
        return tf.keras.callbacks.ModelCheckpoint(
            filepath=os.path.join(self.model_dir, f"{model_name}_best.h5"),
            monitor='val_accuracy',
            save_best_only=True,
            save_weights_only=False,
            mode='max',
            verbose=1
        )

    def train(self, train_x, train_y, valid_x, valid_y, 
              batch_size=32, epochs=100, learning_rate=1e-4, 
              weight_decay=1e-4, model_name="ResNet50"):
        """Training procedure with automatic model saving"""
        # Encode labels
        self.encoder = LabelEncoder()
        train_y_enc = self.encoder.fit_transform(train_y)
        valid_y_enc = self.encoder.transform(valid_y)
        
        # Callbacks
        callbacks = [
            self._get_model_checkpoint(model_name),
            tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
            tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)
        ]
        
        # Compile
        optimizer = tf.keras.optimizers.AdamW(
            learning_rate=learning_rate,
            weight_decay=weight_decay
        )
        self.model.compile(
            optimizer=optimizer,
            loss="sparse_categorical_crossentropy",
            metrics=["accuracy"]
        )
        
        # Train
        history = self.model.fit(
            x=train_x,
            y=train_y_enc,
            batch_size=batch_size,
            epochs=epochs,
            validation_data=(valid_x, valid_y_enc),
            callbacks=callbacks
        )
        
        # Save final model
        self.save_model(model_name)
        return history

    def save_model(self, model_name):
        """Saves the complete model architecture + weights"""
        save_path = os.path.join(self.model_dir, f"{model_name}_final.h5")
        self.model.save(save_path)
        print(f"Model saved to {save_path}")

    def load_model(self, model_path):
        """Loads a saved model"""
        self.model = tf.keras.models.load_model(model_path)
        print(f"Model loaded from {model_path}")
        return self.model

    def evaluate(self, test_x, test_y, model_name="ResNet50", class_names=None):
        """Standardized evaluation with metrics, visualizations and model saving"""
        test_y_enc = self.encoder.transform(test_y)
        y_pred = np.argmax(self.model.predict(test_x), axis=1)
        
        # Calculate metrics
        metrics = calculate_metrics(test_y_enc, y_pred, model_name)
        print_metrics_summary(metrics)
        
        # Generate visualizations
        save_visualizations(
            model=self.model,
            x_data=test_x,
            y_true=test_y_enc,
            y_pred=y_pred,
            model_name=model_name,
            class_names=class_names
        )
        
        return metrics
