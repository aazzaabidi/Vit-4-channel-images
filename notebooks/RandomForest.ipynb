import numpy as np
import os
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV, PredefinedSplit
from utils.metrics import calculate_metrics, print_metrics_summary
from utils.visualization import save_visualizations

def run_random_forest(train_X, valid_X, train_y, valid_y, test_X, test_y, 
                     model_name="RandomForest", class_names=None, 
                     save_dir="saved_models"):
    """
    Train and evaluate Random Forest classifier with framework integration
    
    Args:
        train_X, valid_X, test_X: Input features
        train_y, valid_y, test_y: Target labels
        model_name: Identifier for saving results
        class_names: List of class names for visualization
        save_dir: Directory to save models and results
        
    Returns:
        best_model: Trained RandomForest classifier
        metrics: Dictionary of evaluation metrics
    """
    # Create save directory
    os.makedirs(save_dir, exist_ok=True)
    
    print("\n=== RANDOM FOREST CLASSIFICATION ===")
    
    # Hyperparameter grid
    tuned_parameters = {
        'n_estimators': [50, 100, 200],
        'max_depth': [5, 10, None],
        'min_samples_split': [2, 5],
        'class_weight': ['balanced', None]
    }
    
    # Prepare data for predefined split
    X = np.concatenate((train_X, valid_X), axis=0)
    y = np.concatenate((train_y, valid_y), axis=0)
    test_fold = np.concatenate([
        np.full(train_y.shape[0], -1),  # Training indices
        np.zeros(valid_y.shape[0])      # Validation indices
    ])
    
    # Initialize and fit GridSearchCV
    clf = GridSearchCV(
        estimator=RandomForestClassifier(random_state=42),
        param_grid=tuned_parameters,
        cv=PredefinedSplit(test_fold),
        n_jobs=-1,
        verbose=2,
        scoring='f1_weighted'
    )
    clf.fit(X, y)
    
    # Get best model
    best_model = clf.best_estimator_
    
    # Prepare test data
    if test_X.ndim > 2:  # If image data
        test_X_flat = test_X.reshape(test_X.shape[0], -1)
    else:
        test_X_flat = test_X
    
    # Make predictions
    test_pred = best_model.predict(test_X_flat)
    
    # Calculate metrics using framework function
    metrics = calculate_metrics(test_y, test_pred, model_name)
    
    # Print summary
    print("\n=== BEST PARAMETERS ===")
    print(clf.best_params_)
    print_metrics_summary(metrics)
    
    # Save visualizations
    save_visualizations(
        model=best_model,
        x_data=test_X_flat,
        y_true=test_y,
        y_pred=test_pred,
        model_name=model_name,
        class_names=class_names
    )
    
    # Save the model
    model_path = os.path.join(save_dir, f"{model_name}.joblib")
    joblib.dump(best_model, model_path)
    print(f"\nModel saved to {model_path}")
    
    # Save metrics
    metrics_path = os.path.join(save_dir, f"{model_name}_metrics.txt")
    with open(metrics_path, 'w') as f:
        f.write(f"Best Parameters:\n{clf.best_params_}\n\n")
        f.write("Evaluation Metrics:\n")
        for k, v in metrics.items():
            f.write(f"{k}: {v}\n")
    print(f"Metrics saved to {metrics_path}")
    
    return best_model, metrics

def load_random_forest(model_path):
    """Load a saved RandomForest model"""
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"No model found at {model_path}")
    return joblib.load(model_path)
