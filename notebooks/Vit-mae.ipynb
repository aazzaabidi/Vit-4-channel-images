
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer for Multi-Class Classification (ViT-MAE)\n",
    "This notebook demonstrates the implementation of a Vision Transformer (ViT) for LULC classification using a masked autoencoder (MAE) approach. \n"
   ]
  },{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.metrics import calculate_metrics, print_metrics_summary\n",
    "from utils.visualization import save_visualizations\n",
    "\n",
    "class ViT_MAE:\n",
    "    def __init__(self, input_shape=(23, 4), num_classes=7, model_dir=\"saved_models/vit_mae\", mask_ratio=0.75):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model_dir = model_dir\n",
    "        self.mask_ratio = mask_ratio\n",
    "        os.makedirs(self.model_dir, exist_ok=True)\n",
    "        \n",
    "        # Build MAE components\n",
    "        self.encoder, self.decoder = self._build_mae()\n",
    "        self.classifier = self._add_classification_head()\n",
    "    \n",
    "    def _build_mae(self):\n",
    "        \"\"\"Build MAE encoder-decoder architecture\"\"\"\n",
    "        # Encoder\n",
    "        inputs = layers.Input(shape=self.input_shape)\n",
    "        patches = Patches(patch_size=4)(inputs)  # (None, 6, 16)\n",
    "        \n",
    "        # Masking\n",
    "        self.mask_token = tf.Variable(tf.random.normal([1, 1, 64]), trainable=True)\n",
    "        masked_patches, _ = self._random_masking(patches)\n",
    "        \n",
    "        # Positional embeddings\n",
    "        num_patches = (self.input_shape[0] // 4) * (self.input_shape[1] // 1)\n",
    "        positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "        pos_embed = layers.Embedding(input_dim=num_patches, output_dim=64)(positions)\n",
    "        \n",
    "        # Encoder processing\n",
    "        x = layers.Dense(64)(masked_patches) + pos_embed\n",
    "        for _ in range(6):  # 6 transformer blocks\n",
    "            x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "            x = layers.MultiHeadAttention(num_heads=4, key_dim=16)(x, x)\n",
    "            x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "            x = layers.Dense(128, activation='gelu')(x)\n",
    "            x = layers.Dense(64)(x)\n",
    "        encoder_output = x\n",
    "        \n",
    "        # Decoder\n",
    "        decoder_inputs = layers.Input(shape=(None, 64))\n",
    "        x = layers.Dense(128)(decoder_inputs) + pos_embed\n",
    "        for _ in range(2):  # Shallow decoder\n",
    "            x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "            x = layers.MultiHeadAttention(num_heads=2, key_dim=16)(x, x)\n",
    "            x = layers.Dense(128, activation='gelu')(x)\n",
    "        reconstructed = layers.Dense(16)(x)  # Reconstruct original patch size\n",
    "        \n",
    "        return Model(inputs, encoder_output), Model(decoder_inputs, reconstructed)\n",
    "    \n",
    "    def _add_classification_head(self, trainable=True):\n",
    "        \"\"\"Add classification head with linear probing option\"\"\"\n",
    "        inputs = layers.Input(shape=(None, 64))\n",
    "        \n",
    "        # Linear probe (non-trainable backbone) vs fine-tuning (trainable)\n",
    "        x = layers.GlobalAveragePooling1D()(inputs)\n",
    "        if not trainable:  # Linear probing\n",
    "            x = layers.Lambda(lambda x: tf.stop_gradient(x))(x)\n",
    "        \n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "        return Model(inputs, outputs)\n",
    "    \n",
    "    def train(self, x_train, y_train, x_val, y_val, \n",
    "             mode='fine-tune', epochs=50, batch_size=64):\n",
    "        \"\"\"\n",
    "        Training interface with mode selection:\n",
    "        - 'pretrain': Self-supervised MAE pretraining\n",
    "        - 'fine-tune': Full fine-tuning (default)\n",
    "        - 'linear-probe': Linear probing (frozen encoder)\n",
    "        \"\"\"\n",
    "        if mode == 'pretrain':\n",
    "            return self.pretrain(x_train, epochs=epochs, batch_size=batch_size)\n",
    "        else:\n",
    "            # Rebuild classifier for selected mode\n",
    "            self.classifier = self._add_classification_head(\n",
    "                trainable=(mode == 'fine-tune')\n",
    "            )\n",
    "            return self.finetune(\n",
    "                x_train, y_train, \n",
    "                x_val, y_val,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "    \n",
    "    def pretrain(self, x_train, epochs=100, batch_size=256):\n",
    "        \"\"\"Self-supervised pretraining\"\"\"\n",
    "        # Custom MAE loss (only masked patches)\n",
    "        def mae_loss(y_true, y_pred):\n",
    "            mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "            return tf.reduce_mean(tf.square(y_true - y_pred) * mask)\n",
    "        \n",
    "        # Compile encoder-decoder\n",
    "        mae_model = Model(\n",
    "            inputs=self.encoder.input,\n",
    "            outputs=self.decoder(self.encoder.output)\n",
    "        )\n",
    "        mae_model.compile(optimizer=tf.keras.optimizers.AdamW(1e-4), loss=mae_loss)\n",
    "        \n",
    "        # Train to reconstruct inputs\n",
    "        history = mae_model.fit(\n",
    "            x_train, x_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.ModelCheckpoint(\n",
    "                    os.path.join(self.model_dir, \"pretrained_encoder.h5\"),\n",
    "                    save_best_only=True,\n",
    "                    save_weights_only=True\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        return history\n",
    "    \n",
    "    def finetune(self, x_train, y_train, x_val, y_val, epochs=50, batch_size=64):\n",
    "        \"\"\"Supervised training with selected mode\"\"\"\n",
    "        # Encode labels\n",
    "        self.encoder.trainable = (not isinstance(\n",
    "            self.classifier.layers[1], layers.Lambda\n",
    "        ))  # Freeze for linear probe\n",
    "        \n",
    "        y_train_enc = tf.keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_val_enc = tf.keras.utils.to_categorical(y_val, self.num_classes)\n",
    "        \n",
    "        # Build end-to-end model\n",
    "        model = Model(\n",
    "            inputs=self.encoder.input,\n",
    "            outputs=self.classifier(self.encoder.output)\n",
    "        )\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.AdamW(1e-5),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        history = model.fit(\n",
    "            x_train, y_train_enc,\n",
    "            validation_data=(x_val, y_val_enc),\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.ModelCheckpoint(\n",
    "                    os.path.join(self.model_dir, f\"{'linear' if not self.encoder.trainable else 'finetune'}_model.h5\"),\n",
    "                    save_best_only=True\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        \"\"\"Unified evaluation for both modes\"\"\"\n",
    "        y_test_enc = tf.keras.utils.to_categorical(y_test, self.num_classes)\n",
    "        model = Model(\n",
    "            inputs=self.encoder.input,\n",
    "            outputs=self.classifier(self.encoder.output)\n",
    "        )\n",
    "        \n",
    "        results = model.evaluate(x_test, y_test_enc, verbose=0)\n",
    "        y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "        \n",
    "        metrics = {\n",
    "            'loss': results[0],\n",
    "            'accuracy': results[1],\n",
    "            **calculate_metrics(y_test, y_pred, \"ViT-MAE\")\n",
    "        }\n",
    "        print_metrics_summary(metrics)\n",
    "        \n",
    "        save_visualizations(\n",
    "            model=model,\n",
    "            x_data=x_test,\n",
    "            y_true=y_test,\n",
    "            y_pred=y_pred,\n",
    "            model_name=\"ViT-MAE\"\n",
    "        )\n",
    "        return metrics\n",
    "\n",
    "# Usage Example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize\n",
    "    vit_mae = ViT_MAE(input_shape=(23, 4), num_classes=7)\n",
    "    \n",
    "    # Option 1: Full pretraining + fine-tuning\n",
    "    vit_mae.train(x_train, y_train, x_val, y_val, mode='pretrain', epochs=100)\n",
    "    vit_mae.train(x_train, y_train, x_val, y_val, mode='fine-tune', epochs=50)\n",
    "    \n",
    "    # Option 2: Linear probing only (frozen encoder)\n",
    "    vit_mae.train(x_train, y_train, x_val, y_val, mode='linear-probe', epochs=50)\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics = vit_mae.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
