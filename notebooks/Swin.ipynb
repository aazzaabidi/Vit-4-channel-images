{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swin Transformer for Time Series Classification\n",
    "This notebook implements a Swin Transformer adapted for time series input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# If utils are defined externally, import them\n",
    "# from utils.metrics import calculate_metrics, print_metrics_summary\n",
    "# from utils.visualization import save_visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowAttention(layers.Layer):\n",
    "    def __init__(self, dim, num_heads, window_size):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.scale = (dim // num_heads) ** -0.5\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.qkv = layers.Dense(self.dim * 3)\n",
    "        self.proj = layers.Dense(self.dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        B, H, W, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2], tf.shape(x)[3]\n",
    "        x = tf.reshape(x, [B, H//self.window_size, self.window_size, W//self.window_size, self.window_size, C])\n",
    "        x = tf.transpose(x, [0, 1, 3, 2, 4, 5])\n",
    "        x = tf.reshape(x, [-1, self.window_size*self.window_size, C])\n",
    "\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = tf.split(qkv, 3, axis=-1)\n",
    "        q = tf.reshape(q, [-1, self.window_size**2, self.num_heads, C//self.num_heads])\n",
    "        q = tf.transpose(q, [0, 2, 1, 3])\n",
    "        k = tf.reshape(k, [-1, self.window_size**2, self.num_heads, C//self.num_heads])\n",
    "        k = tf.transpose(k, [0, 2, 1, 3])\n",
    "        v = tf.reshape(v, [-1, self.window_size**2, self.num_heads, C//self.num_heads])\n",
    "        v = tf.transpose(v, [0, 2, 1, 3])\n",
    "\n",
    "        attn = tf.matmul(q, tf.transpose(k, [0, 1, 3, 2])) * self.scale\n",
    "        attn = tf.nn.softmax(attn, axis=-1)\n",
    "        x = tf.matmul(attn, v)\n",
    "        x = tf.transpose(x, [0, 2, 1, 3])\n",
    "        x = tf.reshape(x, [-1, self.window_size, self.window_size, C])\n",
    "\n",
    "        x = tf.reshape(x, [B, H//self.window_size, W//self.window_size, self.window_size, self.window_size, C])\n",
    "        x = tf.transpose(x, [0, 1, 3, 2, 4, 5])\n",
    "        x = tf.reshape(x, [B, H, W, C])\n",
    "\n",
    "        return self.proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformerBlock(layers.Layer):\n",
    "    def __init__(self, dim, num_heads, window_size, shift_size=0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
    "        self.attn = WindowAttention(dim, num_heads, window_size)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
    "        self.mlp = tf.keras.Sequential([\n",
    "            layers.Dense(dim * 4, activation='gelu'),\n",
    "            layers.Dense(dim)\n",
    "        ])\n",
    "        self.shift_size = shift_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.roll(x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x = x + self.attn(self.norm1(shifted_x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMerging(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.norm = layers.LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "    def call(self, x):\n",
    "        B, H, W, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2], tf.shape(x)[3]\n",
    "        x = tf.reshape(x, [B, H//2, 2, W//2, 2, C])\n",
    "        x = tf.transpose(x, [0, 1, 3, 2, 4, 5])\n",
    "        x = tf.reshape(x, [B, H//2, W//2, 4*C])\n",
    "        x = self.norm(x)\n",
    "        x = layers.Dense(2*C)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformer:\n",
    "    def __init__(self, input_shape=(23, 4), num_classes=7, model_dir=\"saved_models/swin\"):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model_dir = model_dir\n",
    "        os.makedirs(self.model_dir, exist_ok=True)\n",
    "        self.model = self._build_model()\n",
    "        self.encoder = LabelEncoder()\n",
    "\n",
    "    def _build_model(self):\n",
    "        inputs = layers.Input(shape=self.input_shape)\n",
    "        x = layers.Reshape((self.input_shape[0], self.input_shape[1], 1))(inputs)\n",
    "        x = layers.Conv2D(64, kernel_size=(4, 1), strides=(4, 1), padding='same')(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-5)(x)\n",
    "\n",
    "        for _ in range(2):\n",
    "            x = SwinTransformerBlock(64, num_heads=4, window_size=7)(x)\n",
    "            x = SwinTransformerBlock(64, num_heads=4, window_size=7, shift_size=3)(x)\n",
    "            x = PatchMerging()(x)\n",
    "\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(128, activation='gelu')(x)\n",
    "        outputs = layers.Dense(self.num_classes, activation='softmax')(x)\n",
    "        return Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Evaluation and Save Methods\n",
    "Add your training and evaluation pipeline here depending on your data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
